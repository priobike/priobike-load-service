import json
import os
import random
import socket
import time
from datetime import datetime

import requests


def log(message):
    """
    Log a message with a timestamp.
    """
    print(f'[{datetime.now()}] {message}', flush=True)


def load_required(key):
    """
    Load a required environment variable.
    """
    value = os.environ.get(key)
    if not value:
        raise ValueError(f'Please provide {key} in the environment')
    return value
    
# Get the basic auth credentials from the environment
username = os.environ.get('PROMETHEUS_BASIC_AUTH_USERNAME')
password = os.environ.get('PROMETHEUS_BASIC_AUTH_PASSWORD')
prometheus_url = load_required('PROMETHEUS_URL')
# Get the node names from the environment
ingress_node_names = load_required('INGRESS_NODE_NAMES').split(',')
worker_node_names = load_required('WORKER_NODE_NAMES').split(',')
stateful_node_names = load_required('STATEFUL_NODE_NAMES').split(',')
# Get the worker info
worker_username = load_required('WORKER_BASIC_AUTH_USER')
worker_password = load_required('WORKER_BASIC_AUTH_PASS')
worker_host = load_required('WORKER_HOST')
worker_port = load_required('WORKER_PORT')

def save_metrics(
    ingress_load,
    worker_load,
    stateful_load,
    recommend_other_backend,
    warning,
    path
):
    """
    Create prometheus metrics.
    """
    content = ""
    
    content = "load_pct{node_type=\"ingress\",} " + str(ingress_load) + "\n"
    content += "load_pct{node_type=\"worker\",} " + str(worker_load) + "\n"
    content += "load_pct{node_type=\"stateful\",} " + str(stateful_load) + "\n"
    
    content += "recommend_other_backend " + str(int(recommend_other_backend)) + "\n"
    content += "warning " + str(int(warning)) + "\n"
    
    with open(path or "metrics.txt", "w") as f:
        f.write(content)

def push_to_workers(file_path):
    """
    Push a file to all workers.
    """
    with open(file_path) as f:
        file_content = f.read()
    for worker_addr_info in socket.getaddrinfo(worker_host, worker_port, proto=socket.IPPROTO_TCP):
        worker_ip = worker_addr_info[4][0]
        # Get only the file name from the path
        upload_file_path = os.path.basename(file_path)
        url = f'http://{worker_ip}:{worker_port}/upload/{upload_file_path}'
        retries = 2
        success = False
        while retries > 0:
            response = requests.put(
                url, 
                data=file_content, 
                auth=(worker_username, worker_password),
                headers={'Content-Type': 'application/json'},
            )
            if response.status_code >= 200 and response.status_code < 300:
                success = True
                log(f'Successfully pushed to worker {worker_ip}')
                break
            log(f'Failed to push to worker {worker_ip}, response: {response.text}')
            random_wait_time = random.randint(1, 5)
            log(f"Retrying in {random_wait_time} seconds...")
            time.sleep(random_wait_time)
            retries -= 1
        if not success:
            raise Exception(f'Failed to push to worker {worker_ip}')
        
def evaluate_warning(ingress_load, worker_load, stateful_load):
    """
    Send a warning message if the CPU usage is too high.
    We include randomness such that not all clients switch to the other backend all at once but with increasing chance the higher the load.
    """
    
    chance_of_recommending_other_backend = 0.0
    warning = False
    
    INGRESS_THRESHOLD = 80 # percent
    WORKER_THRESHOLD = 80 # percent
    STATEFUL_THRESHOLD = 80 # percent
    
    # Increase the chance of sending a warning if the load is higher than the threshold
    if ingress_load > INGRESS_THRESHOLD:
        diff = ingress_load - INGRESS_THRESHOLD
        diff_normalized = diff / (100 - INGRESS_THRESHOLD)
        chance_of_recommending_other_backend += diff_normalized
        warning = True
        
    # Increase the chance of sending a warning if the load is higher than the threshold
    if worker_load > WORKER_THRESHOLD:
        diff = worker_load - WORKER_THRESHOLD
        diff_normalized = diff / (100 - WORKER_THRESHOLD)
        chance_of_recommending_other_backend += diff_normalized
        warning = True
        
    # Increase the chance of sending a warning if the load is higher than the threshold
    if stateful_load > STATEFUL_THRESHOLD:
        diff = stateful_load - STATEFUL_THRESHOLD
        diff_normalized = diff / (100 - STATEFUL_THRESHOLD)
        chance_of_recommending_other_backend += diff_normalized
        warning = True
        
    # Note: If multiple nodes are above the threshold, the chance of using the failover can be greater then 1.
    # This is not a problem.
    
    return warning, random.random() < chance_of_recommending_other_backend

def evaluate_cpu_usage(status_path, metrics_path):
    """
    Fetch the current CPU usage generated by the node exporter from all nodes.

    See: https://github.com/priobike/priobike-prometheus
    """

    query = '(1 - avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[10m]))) * 100 * on(instance) group_left(node_id, node_name) node_meta'
    url = f'{prometheus_url}/api/v1/query_range'
    end_unix = int(time.time())
    start_unix = end_unix - 60 * 2 # 2 minutes ago
    
    params = {
        'query': query,
        'start': start_unix,
        'end': end_unix,
        'step': 60
    }
    log(f'[INFO] Getting data from {url} with params {params}')
    response = requests.get(url, params=params, auth=(username, password) if username and password else None)
    data = response.json()
    
    if 'data' not in data or 'result' not in data['data']:
        log('[WARN] No data found')
        return
    
    def eval(data, node_name):
        for result in data['data']['result']:
            result_node_name = result['metric']['node_name']
            if result_node_name != node_name:
                continue
            cpu_usages = result['values']
            avg_cpu_usage = sum([float(x[1]) for x in cpu_usages]) / len(cpu_usages) if len(cpu_usages) > 0 else 0
            log(f'[INFO] CPU usage for {node_name}: {avg_cpu_usage:.1f}%')
            return avg_cpu_usage
        log(f'[WARN] No data found for {node_name}')
        return 0
    
    ingress_load = sum([eval(data, name) for name in ingress_node_names]) / len(ingress_node_names)
    worker_load = sum([eval(data, name) for name in worker_node_names]) / len(worker_node_names)
    stateful_load = sum([eval(data, name) for name in stateful_node_names]) / len(stateful_node_names)
    warning, recommend_other_backend = evaluate_warning(ingress_load, worker_load, stateful_load)

    load_json = { 
        'timestamp': int(time.time()),
        'recommendOtherBackend': recommend_other_backend,
        'warning': warning,
    }

    with open(status_path or "load.json", "w") as outfile:
        json.dump(load_json, outfile, indent=4)

    push_to_workers(status_path or "load.json")
    
    save_metrics(ingress_load, worker_load, stateful_load, recommend_other_backend, warning, metrics_path)


if __name__ == '__main__':
    import sys

    # Get an optional path under which the data should be saved
    if len(sys.argv) > 1:
        status_path = sys.argv[1]
    else:
        status_path = None
        
    if len(sys.argv) > 2:
        metrics_path = sys.argv[2]
    else:
        metrics_path = None

    evaluate_cpu_usage(status_path, metrics_path)
